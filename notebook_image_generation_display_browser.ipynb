{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a30645",
   "metadata": {},
   "source": [
    "# Image Generation and Display in Browser\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates generating images from textual prompts using a pre-trained model from the Hugging Face's `diffusers` library. It showcases a simple application of terminal-to-web interfaces, particularly useful for backend developers integrating AI-powered image generation into web applications.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, ensure you have the necessary libraries installed. The primary libraries we'll use are `diffusers` for image generation and `torch` as the backend for the model. If you haven't installed these libraries, uncomment and run the following command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec88636a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439.08s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: diffusers in /opt/homebrew/lib/python3.11/site-packages (0.25.1)\n",
      "Requirement already satisfied: torch in /opt/homebrew/lib/python3.11/site-packages (2.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /opt/homebrew/lib/python3.11/site-packages (from diffusers) (6.11.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from diffusers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.2 in /opt/homebrew/lib/python3.11/site-packages (from diffusers) (0.20.2)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from diffusers) (1.26.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.11/site-packages (from diffusers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from diffusers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/homebrew/lib/python3.11/site-packages (from diffusers) (0.4.1)\n",
      "Requirement already satisfied: Pillow in /opt/homebrew/lib/python3.11/site-packages (from diffusers) (10.1.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.11/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.2->diffusers) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.2->diffusers) (23.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/homebrew/lib/python3.11/site-packages (from importlib-metadata->diffusers) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->diffusers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->diffusers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->diffusers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install necessary packages (uncomment if needed)\n",
    "!pip3 install transformers diffusers torch accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057719d0",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cd59a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "import io\n",
    "import webbrowser\n",
    "import base64\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd958b3",
   "metadata": {},
   "source": [
    "## Initialize the Diffusion Pipeline\n",
    "\n",
    "We initialize the diffusion pipeline by loading a pre-trained model to generate images based on textual prompts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e4d20a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:16<00:00,  2.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusionXLPipeline {\n",
       "  \"_class_name\": \"StableDiffusionXLPipeline\",\n",
       "  \"_diffusers_version\": \"0.25.1\",\n",
       "  \"_name_or_path\": \"stabilityai/sdxl-turbo\",\n",
       "  \"feature_extractor\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"force_zeros_for_empty_prompt\": true,\n",
       "  \"image_encoder\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"EulerAncestralDiscreteScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"text_encoder_2\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModelWithProjection\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"tokenizer_2\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = DiffusionPipeline.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float32, variant=\"fp16\")\n",
    "pipeline.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40eef2d",
   "metadata": {},
   "source": [
    "## Define Image Processing Functions\n",
    "\n",
    "We define functions to generate images from prompts and create an HTML page to display these images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "542d7110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(prompt):\n",
    "    \"\"\"\n",
    "    Generates an image based on a prompt and returns a Data URI for the image.\n",
    "    \"\"\"\n",
    "    image = pipeline(prompt=prompt, num_inference_steps=1, guidance_scale=0.0).images[0]\n",
    "    img_buffer = io.BytesIO()\n",
    "    image.save(img_buffer, format='PNG')\n",
    "    img_buffer.seek(0)\n",
    "    data_uri = base64.b64encode(img_buffer.getvalue()).decode('utf-8')\n",
    "    return f'data:image/png;base64,{data_uri}'\n",
    "\n",
    "def create_html_page_with_images(image_urls):\n",
    "    \"\"\"\n",
    "    Creates an HTML page with the given images and opens it in the default web browser.\n",
    "    \"\"\"\n",
    "    # HTML content with basic CSS styling for improved presentation\n",
    "    html_content = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Generated Images Gallery</title>\n",
    "        <style>\n",
    "            body {\n",
    "                margin: 0;\n",
    "                padding: 0;\n",
    "                background-color: #f0f0f0;\n",
    "                font-family: Arial, sans-serif;\n",
    "            }\n",
    "            .gallery {\n",
    "                display: flex;\n",
    "                flex-wrap: wrap;\n",
    "                justify-content: center;\n",
    "                padding: 20px;\n",
    "            }\n",
    "            .gallery img {\n",
    "                margin: 10px;\n",
    "                border: 1px solid #ccc;\n",
    "                border-radius: 5px;\n",
    "                width: auto;\n",
    "                max-width: 300px;\n",
    "                height: auto;\n",
    "            }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1 style=\"text-align: center; margin-top: 20px;\">AI Generated Images Gallery</h1>\n",
    "        <div class=\"gallery\">\n",
    "    \"\"\"\n",
    "    for url in image_urls:\n",
    "        html_content += f'<img src=\"{url}\" alt=\"Generated Image\"/>'\n",
    "    html_content += \"</div></body></html>\"\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".html\", mode=\"w\", encoding=\"utf-8\") as temp_file:\n",
    "        temp_file.write(html_content)\n",
    "        return temp_file.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd8ddf2",
   "metadata": {},
   "source": [
    "### `display_in_browser` Function\n",
    "\n",
    "The `display_in_browser` function is designed to open a specified HTML file in the default web browser. This is particularly useful for viewing generated content, such as images or reports, directly from a Python script or Jupyter Notebook.\n",
    "\n",
    "#### Parameters:\n",
    "\n",
    "- `html_file_path`: A string containing the file path to the HTML file that should be displayed. The path can be absolute or relative to the current working directory.\n",
    "\n",
    "#### Behavior:\n",
    "\n",
    "Upon calling, the function constructs a `file://` URL pointing to the specified HTML file path and instructs the web browser to open this file. If successful, the content of the HTML file will be displayed in a new tab or window of the default web browser.\n",
    "\n",
    "#### Example Usage:\n",
    "\n",
    "```python\n",
    "display_in_browser(\"path/to/your/file.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f486a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_in_browser(html_file_path):\n",
    "    \"\"\"\n",
    "    Opens the given HTML file path in the default web browser.\n",
    "    \"\"\"\n",
    "    webbrowser.open(f'file://{html_file_path}', new=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26119c2",
   "metadata": {},
   "source": [
    "## Running the Demo\n",
    "\n",
    "This section demonstrates the complete workflow, from generating images based on a given prompt to displaying them in a web browser. Follow the steps below to see the magic happen.\n",
    "\n",
    "## Prompt for Image Generation\n",
    "Given the playful theme of our project, we've chosen a whimsical prompt to inspire our AI-powered image generation. The prompt is designed to evoke vibrant and imaginative scenes:\n",
    "\n",
    "    Prompt: \"Create candy land in a handy heaven.\"\n",
    "\n",
    "Note: While there is a character limit for the prompt, exceeding it may result in automatic truncation. To ensure a seamless user experience, consider implementing a text completion feature on the backend to refine user inputs, preventing unintended truncation.\n",
    "\n",
    "## Generating Multiple Images\n",
    "You have the flexibility to generate up to 10 images per session. However, keep in mind that the rendering time varies depending on system performance. Although running image generation tasks in parallel is feasible, it might lead to resource constraints on less powerful systems. For most users, especially during testing phases, generating 1 to 3 images should provide a satisfactory balance between performance and resource usage.\n",
    "\n",
    "   number_of_images = 3  # Recommended setting for testing\n",
    "\n",
    "By tweaking the number_of_images, you can control the output volume to suit your needs, whether for in-depth exploration or quick demonstrations.\n",
    "\n",
    "NOTE: Before executing below block please seleck the arrow to execute the above code. Sometime the code does register immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "954b9838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:38<00:00, 38.82s/it]\n",
      "100%|██████████| 1/1 [00:42<00:00, 42.02s/it]\n",
      "100%|██████████| 1/1 [00:42<00:00, 42.16s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    prompt = \"Create candy land in a handy heaven.\"\n",
    "    number_of_images = 3\n",
    "    image_urls = [process_image(prompt) for _ in range(number_of_images)]\n",
    "    html_page_path = create_html_page_with_images(image_urls)\n",
    "    display_in_browser(html_page_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98459d2b",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates a simple yet powerful way to integrate backend AI processes with frontend web displays, making it easier for developers to visualize outputs directly in a web browser.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a97ce",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
